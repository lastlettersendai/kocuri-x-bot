import os
import time
import random
import schedule
import tweepy
import requests
import re
import json
from datetime import datetime, timedelta
import warnings

from google import genai
from google.genai import types

warnings.filterwarnings("ignore")

# =========================
# åŸºæœ¬è¨­å®šï¼ˆ2ãƒ„ãƒªãƒ¼å›ºå®šãƒ»ã‚†ã‚‹ï¼‰
# =========================
TWEET_LIMIT = 130
MAX_TWEETS_IN_THREAD = 2
MAX_TOTAL_CHARS = TWEET_LIMIT * MAX_TWEETS_IN_THREAD  # 260

# å›ºå®šã®åŸºæº–æ™‚åˆ»ï¼ˆã“ã“ã¯å¤‰ãˆãªã„ï¼‰
POST_TIMES = ["12:30", "21:30"]

# æºã‚‰ãï¼ˆÂ±åˆ†ï¼‰
JITTER_MINUTES = 7

# è¦–ç‚¹ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
VIEWPOINTS = ["å®‰å¿ƒ", "åè«–", "æš´éœ²", "è§£èª¬"]
HISTORY_PATH = "post_history.json"

# =========================
# è¦–ç‚¹å±¥æ­´
# =========================
def load_history():
    if not os.path.exists(HISTORY_PATH):
        return {"last_viewpoint": -1}
    try:
        with open(HISTORY_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {"last_viewpoint": -1}

def save_history(data):
    try:
        with open(HISTORY_PATH, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

def next_viewpoint():
    h = load_history()
    last = int(h.get("last_viewpoint", -1))
    idx = (last + 1) % len(VIEWPOINTS)
    vp = VIEWPOINTS[idx]
    h["last_viewpoint"] = idx
    h["updated_at"] = datetime.now().isoformat(timespec="seconds")
    save_history(h)
    return vp

# =========================
# Geminiï¼šã»ã¼è‡ªç”±ã«ä¸‹æ›¸ãï¼ˆè¦–ç‚¹ã ã‘æŒ‡å®šï¼‰
# =========================
def gemini_draft(gemini_client, viewpoint: str) -> str:
    viewpoint_rule = {
        "å®‰å¿ƒ": "å®‰å¿ƒã•ã›ã‚‹è¦–ç‚¹ã€‚æ•µã§ã¯ãªã„/å®ˆã‚Šã®åå¿œ/ä½™ç™½ã€‚çµè«–ã¯é™ã‹ã«ã€‚",
        "åè«–": "èª¤è§£ã¸ã®åè«–ã®è¦–ç‚¹ã€‚æ€§æ ¼ã®ã›ã„ãƒ»æ ¹æ€§è«–ã‚’ã‚„ã•ã—ãå¦å®šã—ã€èº«ä½“ã®åå¿œã«æˆ»ã™ã€‚",
        "æš´éœ²": "å›³æ˜Ÿã‚’è¨€ã†è¦–ç‚¹ã€‚ã¡ã‚ƒã‚“ã¨ã—ã™ã/æˆ‘æ…¢/åŠ›ã¿ã‚’è¨€èªåŒ–ã—ã¦ã€è²¬ã‚ãšã«æ•‘ã†ã€‚",
        "è§£èª¬": "ç¾è±¡è§£èª¬ã®è¦–ç‚¹ã€‚é¦–ãƒ»å–‰ãƒ»å‘¼å¸ãƒ»ã¿ããŠã¡ç­‰ã®å…·ä½“â†’æ—¥å¸¸å ´é¢â†’ã€åˆ‡ã‚Šæ›¿ãˆã€ã®è©±ã¸ã€‚"
    }[viewpoint]

    prompt = f"""
ã‚ãªãŸã¯ã€Œæ•´ä½“é™¢ã‚³ã‚¯ãƒªã€é™¢é•·ã®ãƒŠãƒ™ã‚¸ãƒ¥ãƒ³ã€‚
ãƒ‘ãƒ‹ãƒƒã‚¯éšœå®³ã¨è´è¦šéšœå®³ã®å½“äº‹è€…çµŒé¨“ã‚’èƒŒæ™¯ã«ã€
è‡ªå¾‹ç¥çµŒã®ä¸èª¿ã‚„éç·Šå¼µã‚’â€œèº«ä½“ã®åå¿œâ€ã¨ã—ã¦æ‰±ã†æ•´ä½“å¸«ã§ã™ã€‚

ä»Šå›ã¯ã®è¦–ç‚¹ã§ã€XæŠ•ç¨¿ã®ä¸‹æ›¸ãã‚’1æœ¬æ›¸ã„ã¦ãã ã•ã„ã€‚
æ–‡ç« æ§‹é€ ã¯è‡ªç”±ã€‚çŸ­æ–‡ã‚’æ•£ã‚‰ã—ã™ããªãã¦OKã€‚èªã‚‹æ„Ÿã˜ã§ã‚‚OKã€‚

ã€ä»Šå›ã®è¦–ç‚¹ãƒ¡ãƒ¢ã€‘
{viewpoint_rule}

ã€ãƒŠãƒ™ã‚¸ãƒ¥ãƒ³æ†²æ³•ï¼ˆå¿…ãšå®ˆã‚‹ï¼‰ã€‘
ãƒ»ç—‡çŠ¶ã¯æ•µã§ã¯ãªãã€ã¾ãšå®ˆã‚Šã®åå¿œã¨ã—ã¦æ‰±ã†
ãƒ»ã€Œæ²»ã™/å®Œæ²»/å¿…ãšã€ãªã©æ–­è¨€ã—ãªã„ï¼ˆå›å¾©ã®åœŸå°ã‚’æ•´ãˆã‚‹ï¼‰
ãƒ»å¼·ã„åˆºæ¿€ã‚„æŠ¼ã—ä»˜ã‘ã®è¡¨ç¾ã‚’é¿ã‘ã€èº«ä½“ã®å®‰å…¨ã‚’æœ€å„ªå…ˆ
ãƒ»å¦å®šã—ãªã„ï¼ç„¦ã‚‰ã›ãªã„ï¼æŠ¼ã—ä»˜ã‘ãªã„
ãƒ»ç²¾ç¥è«–ã«ã—ãªã„ï¼ˆéç·Šå¼µï¼èº«ä½“ã®ã‚·ã‚¹ãƒ†ãƒ å´ã®è©±ã¨ã—ã¦æãï¼‰
ãƒ»æœ€å¾Œã¯å®‰å¿ƒã®ä½™ç™½ã§é™ã‹ã«ç· ã‚ã‚‹ï¼ˆèª¬æ•™ã—ãªã„ï¼‰

ã€ã‚†ã‚‹æ¡ä»¶ã€‘
ãƒ»ãƒ†ãƒ¼ãƒè‡ªç”±ï¼ˆæ€æƒ³ã€ç—‡çŠ¶ã€æ—¥å¸¸ã®æ°—ã¥ããªã©ï¼‰
ãƒ»çµµæ–‡å­—/ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°/ç•ªå·ï¼ˆ1/2ãªã©ï¼‰ç¦æ­¢
ãƒ»å£²ã‚Šè¾¼ã¿ç¦æ­¢ï¼ˆäºˆç´„/æ¥é™¢/ä¾¡æ ¼/ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«èª˜å°ãªã©ç¦æ­¢ï¼‰
ãƒ»æœ€å¤§{MAX_TOTAL_CHARS}æ–‡å­—ä»¥å†…ï¼ˆçŸ­ã„ã®ã¯OKï¼‰
""".strip()

    r = gemini_client.models.generate_content(
        model="gemini-3-flash-preview",
        contents=prompt,
        config=types.GenerateContentConfig(temperature=1.2)
    )
    return (r.text or "").strip()

# =========================
# ChatGPTï¼šè»½ãæ•´ãˆã‚‹ï¼ˆä½œã‚Šå¤‰ãˆãªã„ï¼‰
# =========================
def chatgpt_polish(text: str) -> str:
    key = os.getenv("OPENAI_API_KEY")
    if not key:
        return text

    model = os.getenv("OPENAI_MODEL", "gpt-5.2")

    prompt = f"""
ã‚ãªãŸã¯XæŠ•ç¨¿ã®ç·¨é›†è€…ã§ã™ã€‚
ä¸‹æ›¸ãã‚’è‡ªç„¶ã«æ•´ãˆã¦ãã ã•ã„ã€‚
å¤§ããä½œã‚Šå¤‰ãˆãšã€æ¸©åº¦ã¯æ®‹ã™ã€‚

ã€ã‚„ã‚‹ã“ã¨ã€‘
ãƒ»èª­ã¿ã‚„ã™ãæ•´ãˆã‚‹
ãƒ»ä¸è‡ªç„¶ãªé‡è¤‡ãŒã‚ã‚Œã°å‰Šã‚‹ï¼ˆåŒã˜æ–‡ã‚’2å›æ›¸ã‹ãªã„ï¼‰
ãƒ»å£²ã‚Šè¾¼ã¿ã‚’å…¥ã‚Œãªã„
ãƒ»çµµæ–‡å­—/ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°/ç•ªå·ã‚’å…¥ã‚Œãªã„
ãƒ»æœ€å¤§{MAX_TOTAL_CHARS}æ–‡å­—ä»¥å†…

å®Œæˆæ–‡ã®ã¿å‡ºåŠ›ã€‚

ã€ä¸‹æ›¸ãã€‘
{text}
""".strip()

    headers = {"Authorization": f"Bearer {key}", "Content-Type": "application/json"}
    payload = {"model": model, "input": prompt}

    try:
        r = requests.post("https://api.openai.com/v1/responses", headers=headers, json=payload, timeout=30)
        r.raise_for_status()
        data = r.json()

        if isinstance(data.get("output_text"), str):
            out = data["output_text"].strip()
        else:
            out = ""
            for item in data.get("output", []):
                for c in item.get("content", []):
                    if c.get("type") in ("output_text", "text"):
                        out += c.get("text", "")
            out = (out or "").strip() or text

        if len(out) > MAX_TOTAL_CHARS:
            out = out[:MAX_TOTAL_CHARS].rstrip()

        return out

    except Exception:
        return text

# =========================
# é€£ç¶šåŒä¸€è¡Œã ã‘æœ€å°é™ã§æ½°ã™ï¼ˆä¿é™ºï¼‰
# =========================
def remove_consecutive_duplicate_lines(text: str) -> str:
    if not text:
        return text
    lines = [l.rstrip() for l in text.split("\n")]
    out = []
    prev = None
    for l in lines:
        if l and prev == l:
            continue
        out.append(l)
        if l:
            prev = l
    return "\n".join(out).strip()

# =========================
# 2ãƒ„ãƒªãƒ¼å›ºå®šã®åˆ†å‰²ï¼ˆä½™ã‚Šmergeãªã—ï¼‰
# =========================
def split_into_thread(text: str):
    text = (text or "").strip()
    if not text:
        return []

    if len(text) > MAX_TOTAL_CHARS:
        text = text[:MAX_TOTAL_CHARS].rstrip()

    if len(text) <= TWEET_LIMIT:
        return [text]

    window = text[:TWEET_LIMIT]
    cut = -1
    for m in re.finditer(r"[\nã€‚ï¼ï¼Ÿ!?]", window):
        cut = m.end()

    if cut < 20:
        cut = TWEET_LIMIT

    part1 = text[:cut].strip()
    part2 = text[cut:].strip()

    return [p for p in [part1, part2] if p]

# =========================
# æŠ•ç¨¿å‡¦ç†
# =========================
def job():
    print(f"--- æŠ•ç¨¿é–‹å§‹: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ---")

    missing = [k for k in ["API_KEY","API_SECRET","ACCESS_TOKEN","ACCESS_TOKEN_SECRET","GEMINI_API_KEY"] if not os.getenv(k)]
    if missing:
        print(f"ç’°å¢ƒå¤‰æ•°ä¸è¶³: {missing}")
        return

    try:
        gemini_client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

        viewpoint = next_viewpoint()
        print(f"ã€ä»Šå›ã®è¦–ç‚¹ã€‘{viewpoint}")

        draft = gemini_draft(gemini_client, viewpoint=viewpoint)
        final = chatgpt_polish(draft)
        final = remove_consecutive_duplicate_lines(final)

        if not final:
            final = "ã¡ã‚ƒã‚“ã¨ã—ã™ãã‚‹äººã»ã©ã€ä½“ãŒå…ˆã«æ­¢ã¾ã‚‹ã€‚"

        print("ã€å®Œæˆæ–‡ã€‘\n", final)

        parts = split_into_thread(final)
        if not parts:
            print("ç”Ÿæˆå¤±æ•—ï¼ˆç©ºï¼‰")
            return

        client_x = tweepy.Client(
            consumer_key=os.getenv("API_KEY"),
            consumer_secret=os.getenv("API_SECRET"),
            access_token=os.getenv("ACCESS_TOKEN"),
            access_token_secret=os.getenv("ACCESS_TOKEN_SECRET")
        )

        first = client_x.create_tweet(text=parts[0])
        last_id = first.data["id"]

        for p in parts[1:]:
            resp = client_x.create_tweet(text=p, in_reply_to_tweet_id=last_id)
            last_id = resp.data["id"]

        print(f"âœ… æŠ•ç¨¿æˆåŠŸï¼ï¼ˆ{len(parts)}ãƒ„ãƒªãƒ¼ï¼‰")

    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")

# =========================
# æºã‚‰ãã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆæ¯æ—¥ä½œã‚Šç›´ã™ï¼‰
# =========================
def jitter_time_str(base_hhmm: str, jitter_minutes: int) -> str:
    """
    base_hhmm (ä¾‹ '12:30') ã«å¯¾ã—ã¦ Â±jitter_minutes ã®ç¯„å›²ã§ãƒ©ãƒ³ãƒ€ãƒ ã«æºã‚‰ã™ã€‚
    è¿”ã‚Šå€¤ã¯ 'HH:MM'ã€‚
    """
    h, m = map(int, base_hhmm.split(":"))
    base = datetime(2000, 1, 1, h, m)
    offset = random.randint(-jitter_minutes, jitter_minutes)
    t = base + timedelta(minutes=offset)
    return t.strftime("%H:%M")

def schedule_today_with_jitter():
    """
    å½“æ—¥åˆ†ã®æŠ•ç¨¿ã‚’ã€åŸºæº–POST_TIMESã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«æºã‚‰ã—ã¦ç™»éŒ²ã™ã‚‹ã€‚
    schedule.clear('posts')ã§æ¯æ—¥ä½œã‚Šç›´ã™å‰æã€‚
    """
    schedule.clear('posts')
    actual_times = []
    for base in POST_TIMES:
        actual = jitter_time_str(base, JITTER_MINUTES)
        schedule.every().day.at(actual).do(job).tag('posts')
        actual_times.append((base, actual))
    print("ğŸ“Œ æœ¬æ—¥ã®æŠ•ç¨¿æ™‚åˆ»ï¼ˆæºã‚‰ãé©ç”¨ï¼‰:", ", ".join([f"{b}â†’{a}" for b, a in actual_times]))

def reschedule_job():
    """
    æ—¥ä»˜ãŒå¤‰ã‚ã£ãŸã‚‰å½“æ—¥åˆ†ã®æŠ•ç¨¿æ™‚åˆ»ã‚’ä½œã‚Šç›´ã™ã€‚
    00:01ã«å®Ÿè¡Œã€‚
    """
    schedule_today_with_jitter()

# =========================
# èµ·å‹•
# =========================
print(f"2ãƒ„ãƒªãƒ¼å›ºå®šÃ—è¦–ç‚¹ãƒ­ãƒ¼ãƒ† èµ·å‹•å®Œäº†ï¼ˆ1æ—¥{len(POST_TIMES)}å› / 130å­—Ã—æœ€å¤§2 / 4è¦–ç‚¹ï¼‰")
print(f"æºã‚‰ãï¼šÂ±{JITTER_MINUTES}åˆ† / åŸºæº–æ™‚åˆ»: {POST_TIMES}")

# å½“æ—¥åˆ†ã‚’ç™»éŒ²
schedule_today_with_jitter()

# æ¯æ—¥0:01ã«ç¿Œæ—¥ã®æºã‚‰ãã‚’ä½œã‚Šç›´ã™ï¼ˆã‚¿ã‚°ã”ã¨ä½œã‚Šç›´ã—ï¼‰
schedule.every().day.at("00:01").do(reschedule_job)

# ãƒ‡ãƒ—ãƒ­ã‚¤æ™‚ã«å³æŠ•ç¨¿ã—ãŸã„å ´åˆã ã‘ï¼ˆä»»æ„ï¼‰
if os.getenv("DEPLOY_RUN", "0") == "1":
    job()

while True:
    schedule.run_pending()
    time.sleep(30)
